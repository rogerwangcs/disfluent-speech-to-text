
######################## PREPARE FILES ########################

rm -rf data/train
mkdir data/train
rm -rf data/test
mkdir data/test

python split_data.py
python prepare_files.py data/train data/test
utils/utt2spk_to_spk2utt.pl data/train/utt2spk > data/train/spk2utt
utils/utt2spk_to_spk2utt.pl data/test/utt2spk > data/test/spk2utt

### PREAPRE DATA/LOCAL/LANG FILES ###

cd data/local/lang
wget http://svn.code.sf.net/p/cmusphinx/code/trunk/cmudict/sphinxdict/cmudict_SPHINX_40
echo -e 'oov\toov' > lexicon.txt
tr -d $'\r' < cmudict_SPHINX_40 >> lexicon.txt

cut -d ' ' -f 2- lexicon.txt | \sed 's/ /\n/g' | \sort -u > nonsilence_phones.txt
sed -i 's/\t/\n/g' nonsilence_phones.txt
sed -i '/oov/d' nonsilence_phones.txt
sort -u nonsilence_phones.txt > nonsilence_phones_NEW.txt
mv nonsilence_phones_NEW.txt nonsilence_phones.txt
echo -e 'SIL\noov' > silence_phones.txt
echo 'SIL' > optional_silence.txt

### CREATE FILES FOR DATA/LANG ###

cd ../../..
rm data/local/lang/lexiconp.txt
utils/prepare_lang.sh data/local/lang 'oov' data/local/ data/lang


######################## EXTRACT MFCC ########################

export train_cmd=run.pl
export decode_cmd="run.pl --mem 4G"
export mkgraph_cmd="run.pl --mem 8G"
export cuda_cmd="run.pl --gpu 1"
mfccdir=mfcc
steps/make_mfcc.sh --cmd "$train_cmd" --nj 4 data/train exp/make_mfcc/data/train $mfccdir
steps/make_mfcc.sh --cmd "$train_cmd" --nj 4 data/test exp/make_mfcc/data/test $mfccdir
steps/compute_cmvn_stats.sh data/train exp/make_mfcc/data/train $mfccdir
steps/compute_cmvn_stats.sh data/test exp/make_mfcc/data/test $mfccdir

utils/validate_data_dir.sh data/train
utils/validate_data_dir.sh data/test

### CONFIG ###

echo -e "--sample-frequency=22050\n--use-energy=false\n--num-mel-bins=40\n--num-ceps=40\n--low-freq=20\n--high-freq=-400" > conf/mfcc.conf



########################### DUMMIES ###########################
https://kaldi-asr.org/doc/kaldi_for_dummies.html#kaldi_for_dummies_configuration

### INSTALL SRILM ###

https://drive.google.com/file/d/1tknj-XtyFbKPyuxqs02G0Lk6GBBgCg-U/view?usp=sharing

docker cp /Users/christine/Downloads/srilm-1.7.3.tar.gz dc4201c66bfc:/opt/kaldi/tools

cd ../../tools
apt-get install gawk
mv srilm-1.7.3.tar.gz srilm.tar.gz
bash install_srilm.sh
cd ../egs/disfluent-speech-to-text
source ../../tools/env.sh


### MAKE LM.ARPA ###

loc=`which ngram-count`;
sdir=$KALDI_ROOT/tools/srilm/bin/i686-m64
echo "Using SRILM language modelling tool from $sdir"
export PATH=$PATH:$sdir

local=data/local
lang=data/lang
mkdir data/local/tmp
ngram-count -write-vocab $local/tmp/vocab-full.txt -wbdiscount -text /local/lang/lexicon.txt -lm /local/tmp/lm.arpa


### MAKE G.FST ###

cp data/words.txt data/lang/words.txt 
../../src/lmbin/arpa2fst --disambig-symbol=#0 --read-symbol-table=data/lang/words.txt data/local/tmp/lm.arpa data/lang/G.fst


### MONOPHONES TRAIN + TEST ###

steps/train_mono.sh --nj 3 --cmd "$train_cmd" data/train data/lang exp/mono
utils/mkgraph.sh --mono data/lang exp/mono exp/mono/graph
steps/decode.sh --config conf/decode.config --nj 3 --cmd "$decode_cmd" exp/mono/graph data/test exp/mono/decode

steps/score_kaldi.sh --cmd "run.pl" data/test exp/mono exp/mono/decode
cat exp/mono/decode/scoring_kaldi/best_wer


### TRIPHONES TRAIN + TEST ###

steps/align_si.sh --nj 3 --cmd "$train_cmd" data/train data/lang exp/mono exp/mono_ali
steps/train_deltas.sh --cmd "$train_cmd" 2000 11000 data/train data/lang exp/mono_ali exp/tri1
utils/mkgraph.sh data/lang exp/tri1 exp/tri1/graph
steps/decode.sh --config conf/decode.config --nj 3 --cmd "$decode_cmd" exp/tri1/graph data/test exp/tri1/decode

steps/score_kaldi.sh --cmd "run.pl" data/test exp/tri1 exp/tri1/decode
cat exp/tri1/decode/scoring_kaldi/best_wer

the end!







######################## PRE-TRAINED LIBRISPEECH MODEL ########################

### CONFIG ###

echo -e "--sample-frequency=22050\n--use-energy=false\n--num-mel-bins=40\n--num-ceps=40\n--low-freq=20\n--high-freq=-400" > conf/mfcc.conf


### EXTRACT MFCC ###

steps/make_mfcc.sh --nj 1 --mfcc-config conf/mfcc.conf --cmd "$train_cmd" data/test_eval
steps/compute_cmvn_stats.sh data/test_eval

utils/fix_data_dir.sh data/test_eval


### DOWNLOAD MODEL ###

wget http://kaldi-asr.org/models/13/0013_librispeech_s5.tar.gz
tar -xvzf 0013_librispeech_s5.tar.gz

cp -r 0013_librispeech_v1/data/lang_test* data/
cp -r 0013_librispeech_v1/exp .

### EXTRACT I-VECTORS ###

steps/online/nnet2/extract_ivectors_online.sh --cmd "$train_cmd" --nj 1 data/test_eval exp/nnet3_cleaned/extractor exp/nnet3_cleaned/ivectors_test_eval


### MAKE GRAPHS ###

utils/mkgraph.sh --self-loop-scale 1.0 --remove-oov data/lang_test_eval_tgsmall $dir $graph_dir


### DECODE ###

export decode_cmd="run.pl --mem 2G"

steps/nnet3/decode.sh --acwt 1.0 --post-decode-acwt 10.0 --nj 2 --cmd "$decode_cmd" --online-ivector-dir exp/nnet3_cleaned/ivectors_test_eval $graph_dir data/test_eval $dir/decode_test_eval_tgsmall


### GET WER ###

steps/score_kaldi.sh --cmd "run.pl" data/test_eval $graph_dir $dir/decode_test_eval_tgsmall

export dir=exp/chain_cleaned/tdnn_1d_sp
export graph_dir=$dir/graph_tgsmall
steps/score_kaldi.sh --cmd "run.pl" data/test_eval $graph_dir $dir/decode_test_eval_tgsmall

cat exp/chain_cleaned/tdnn_1d_sp/decode_test_eval_tgsmall/scoring_kaldi/best_wer


the end!




######## DOCKER ########

docker exec -it inspiring_yalow /bin/bash

docker container ls

docker cp ~/Downloads/foo.txt dc4201c66bfc:/opt/kaldi/egs/disfluent-speech-to-text

tar xvzf augmented-data-big.tar.gz


######## AWS ########

brew install awscli

aws configure
[get key from roger]
[get secret key from roger]
us-east-1
text

mv key.pem zhongVirginia.pem
chmod 400 zhongVirginia.pem
bash aws.bash 'connect'

rsync -am -e "ssh -i ~/.keys/zhongVirginia.pem" ~/Downloads/srilm-1.7.3.tar.gz ubuntu@ec2-34-237-52-132.compute-1.amazonaws.com:/home/ubuntu/kaldi/tools



######## FORMAT .WAV FILES: ########

### CHECK FORMAT ###

sox -V *.wav -n

### CONVERT FOR ALL SPEAKERS ###
(run from inside augmented-data-big)

cd augmented-data-big

for dir in */
	do
	for x in ./$dir/*.wav
	do
		b=${x##*/}
		sox $dir$b -r 16000 $dir+tmp_$b && sox $dir$b -b 16 $dir+tmp_$b
		rm -rf $dir$b
		mv $dir+tmp_$b $dir$b
	done
done

bash fs.sh

### CONVERT FOR ONE SPEAKER ###
(run from inside the speaker folder)

for x in ./*.wav
do
	b=${x##*/}
	sox $b -r 16000 tmp_$b && sox $b -b 16 tmp_$b
	rm -rf $b
	mv tmp_$b $b
done








